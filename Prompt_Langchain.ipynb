{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzamap4yAin905mVZYZ/ra",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kira1108/PromptEngineering/blob/main/Prompt_Langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**你需要做的就是非常耐心的，特别耐心的写好自己的Prompt**     \n",
        "**写好以后，你就只需要用到这个prompt的format方法就够了**    \n",
        "**这个format方法接受你提供的内容文本， 作为参数 `kwargs`**。  "
      ],
      "metadata": {
        "id": "giootc9BoRmY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jv_JO1eZaF_6"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install openai langchain sentencepiece tiktoken\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Prompt Template Class"
      ],
      "metadata": {
        "id": "PDMfxg9neYa7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "class BasePromptTemplate:\n",
        "\n",
        "    # (Factory method) use this method to create a prompt template\n",
        "    @classmethod\n",
        "    def from_template(cls, str) -> BasePromptTemplate:\n",
        "        ...\n",
        "\n",
        "    # use this method to return a prompt value(usually inside langchian)\n",
        "    def format_prompt(self, **input_variables) -> PromptValue:\n",
        "        ...\n",
        "\n",
        "    # get a string prompt and return as string for llms\n",
        "    def format(self, **input_variables) -> string:\n",
        "        ...\n",
        "\n",
        "class PromptValue:\n",
        "    \"\"\"Finally llms only understand string input or messages input(chat models)\"\"\"\n",
        "    def to_string(self) -> str:\n",
        "        ...\n",
        "\n",
        "    def to_messages(self) -> list[Messages]:\n",
        "        ...\n",
        "```"
      ],
      "metadata": {
        "id": "_qplQ9WGeTlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate"
      ],
      "metadata": {
        "id": "bCh5BF78abOA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in this prompt template,the input variables ['story', 'emotion'] is automatically parsed\n",
        "prompt = PromptTemplate.from_template(\"Tell me a story about {topic}, with emotion {emotion}\")\n",
        "print(prompt.input_variables) \n",
        "print(prompt.format(topic = \"Dog\", emotion = 'angry'))\n",
        "\n",
        "# use chat prompt the same way as promptTempate, except that this prompt is frmo the user role\n",
        "chat_prompt = ChatPromptTemplate.from_template(\"Tell me a story about a {topic} with emotion {emotion}\")\n",
        "print(chat_prompt.input_variables)\n",
        "print(chat_prompt.format(topic = \"Dog\", emotion ='angry'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJhDWb9qbl-2",
        "outputId": "3c395f90-33e2-4eda-baa6-40f353d9d28c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['emotion', 'topic']\n",
            "Tell me a story about Dog, with emotion angry\n",
            "['topic', 'emotion']\n",
            "Human: Tell me a story about a Dog with emotion angry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in this prompt template,the input variables ['story', 'emotion'] is automatically parsed\n",
        "prompt = PromptTemplate.from_template(\"Tell me a story about {topic}, with emotion {emotion}\")\n",
        "print(\"Prompt Template\")\n",
        "print(prompt.input_variables)\n",
        "print(prompt.format_prompt(topic = \"Dog\", emotion = 'angry'))\n",
        "\n",
        "print(\"-\"*20)\n",
        "\n",
        "print(\"Chat Prompt Template\")\n",
        "# use chat prompt the same way as promptTempate, except that this prompt is frmo the user role\n",
        "chat_prompt = ChatPromptTemplate.from_template(\"Tell me a story about a {topic} with emotion {emotion}\")\n",
        "print(chat_prompt.input_variables)\n",
        "print(chat_prompt.format_prompt(topic = \"Dog\", emotion ='angry'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wel7kbKicbzz",
        "outputId": "64773e39-063c-4f52-d519-4a3ecfcbcf36"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt Template\n",
            "['emotion', 'topic']\n",
            "text='Tell me a story about Dog, with emotion angry'\n",
            "--------------------\n",
            "Chat Prompt Template\n",
            "['topic', 'emotion']\n",
            "messages=[HumanMessage(content='Tell me a story about a Dog with emotion angry', additional_kwargs={}, example=False)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting to string or messages"
      ],
      "metadata": {
        "id": "o7G77Z9QdkpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_string_result = prompt.format_prompt(topic = \"Dog\", emotion = 'angry').to_string()\n",
        "to_messages_result = prompt.format_prompt(topic = \"Dog\", emotion = 'angry').to_messages()\n",
        "print(type(to_string_result),\": \", to_string_result)\n",
        "print(type(to_messages_result),\": \", to_messages_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HlxPCeTdfyh",
        "outputId": "96f9e942-c853-4359-9c19-b4a5c70846d3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'> :  Tell me a story about Dog, with emotion angry\n",
            "<class 'list'> :  [HumanMessage(content='Tell me a story about Dog, with emotion angry', additional_kwargs={}, example=False)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_string_result = chat_prompt.format_prompt(topic = \"Dog\", emotion = 'angry').to_string()\n",
        "to_messages_result = chat_prompt.format_prompt(topic = \"Dog\", emotion = 'angry').to_messages()\n",
        "print(type(to_string_result),\": \", to_string_result)\n",
        "print(type(to_messages_result),\": \", to_messages_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7WglMirew_x",
        "outputId": "ad67a108-901a-4c31-c031-728ad527021f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'> :  Human: Tell me a story about a Dog with emotion angry\n",
            "<class 'list'> :  [HumanMessage(content='Tell me a story about a Dog with emotion angry', additional_kwargs={}, example=False)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practice\n",
        "\n",
        "\n",
        "A PromptTemplate requires 2 arguments `template` and `input_variables`"
      ],
      "metadata": {
        "id": "UJioLC1Sjm76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"What is the fuking wrong with {person}\"\n",
        "\n",
        "# use the constructor\n",
        "pt = PromptTemplate(template = template, input_variables = ['person'])\n",
        "wanghuan_prompt = pt.format(person = \"Wang Huan\")\n",
        "print(wanghuan_prompt)\n",
        "print(pt.format(person = \"Your Mother!\"))\n",
        "print(pt.format(person = \"Your Daddy!\"))\n",
        "print(pt.format(person = \"Your Grandpa\"))\n",
        "\n",
        "# or simple use this factory method\n",
        "fucking_girl_friend = PromptTemplate.from_template(template).format(person = \"my girl friend\")\n",
        "print(fucking_girl_friend)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzXkbbtcez3W",
        "outputId": "9115edf6-d645-44af-f13e-4c1b5b851da6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the fuking wrong with Wang Huan\n",
            "What is the fuking wrong with Your Mother!\n",
            "What is the fuking wrong with Your Daddy!\n",
            "What is the fuking wrong with Your Grandpa\n",
            "What is the fuking wrong with my girl friend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Love Jinja `{{}}`more than Python f-string"
      ],
      "metadata": {
        "id": "tTwhS1EHmApJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jinja_str = \"Hi {{person}}, what's the fuking wrong with {{other_person}}.\"\n",
        "\n",
        "jinja_template = PromptTemplate.from_template(jinja_str, template_format = 'jinja2')\n",
        "jinja_template.format(person = \"Huan\", other_person = \"your wife\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "S6uv7oRvko0J",
        "outputId": "f97823c9-c4c7-4d7a-e213-36d121851106"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi Huan, what's the fuking wrong with your wife.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save and load prompts"
      ],
      "metadata": {
        "id": "G1B6QzXFn7xj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jinja_template.save(\"jp.json\")\n",
        "!cat jp.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaOtcjs6mP7H",
        "outputId": "6fff3560-1f4b-41a0-bebe-95d14c7ac833"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"input_variables\": [\n",
            "        \"other_person\",\n",
            "        \"person\"\n",
            "    ],\n",
            "    \"output_parser\": null,\n",
            "    \"partial_variables\": {},\n",
            "    \"template\": \"Hi {{person}}, what's the fuking wrong with {{other_person}}.\",\n",
            "    \"template_format\": \"jinja2\",\n",
            "    \"validate_template\": true,\n",
            "    \"_type\": \"prompt\"\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pt.save(\"pt.json\")\n",
        "!cat pt.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzpM45LnmuXz",
        "outputId": "c655f895-9377-4922-c1d8-ee3681903d32"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"input_variables\": [\n",
            "        \"person\"\n",
            "    ],\n",
            "    \"output_parser\": null,\n",
            "    \"partial_variables\": {},\n",
            "    \"template\": \"What is the fuking wrong with {person}\",\n",
            "    \"template_format\": \"f-string\",\n",
            "    \"validate_template\": true,\n",
            "    \"_type\": \"prompt\"\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import load_prompt"
      ],
      "metadata": {
        "id": "USwcv8SznoOT"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_prompt(\"pt.json\").format(person = \"wanghuan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0WVZ8sLwnrlh",
        "outputId": "7cfe528c-612d-4a0f-e576-34248171c0a2"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the fuking wrong with wanghuan'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_prompt(\"jp.json\").format(person = 'wanghuan',other_person = \"my wife\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_2am6NDWntRh",
        "outputId": "8a19ec03-364e-40e0-841e-730a46a16860"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi wanghuan, what's the fuking wrong with my wife.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ]
}